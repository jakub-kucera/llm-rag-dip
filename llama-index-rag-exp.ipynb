{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T14:06:57.125462Z",
     "start_time": "2024-06-02T14:06:36.842144Z"
    }
   },
   "source": [
    "from llama_index.core.llama_dataset import (\n",
    "    LabelledRagDataExample,\n",
    "    CreatedByType,\n",
    "    CreatedBy,\n",
    ")\n",
    "\n",
    "# constructing a LabelledRagDataExample\n",
    "query = \"This is a test query, is it not?\"\n",
    "query_by = CreatedBy(type=CreatedByType.AI, model_name=\"gpt-4\")\n",
    "reference_answer = \"Yes it is.\"\n",
    "reference_answer_by = CreatedBy(type=CreatedByType.HUMAN)\n",
    "reference_contexts = [\"This is a sample context\"]\n",
    "\n",
    "rag_example = LabelledRagDataExample(\n",
    "    query=query,\n",
    "    query_by=query_by,\n",
    "    reference_contexts=reference_contexts,\n",
    "    reference_answer=reference_answer,\n",
    "    reference_answer_by=reference_answer_by,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakubkucera_1/Documents/diplomka/llm-rag-dip/.venv/lib/python3.12/site-packages/llama_index_client/types/metadata_filter.py:20: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:06:57.132988Z",
     "start_time": "2024-06-02T14:06:57.128529Z"
    }
   },
   "cell_type": "code",
   "source": "print(rag_example.json())",
   "id": "e633d8486ce944f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"This is a test query, is it not?\", \"query_by\": {\"model_name\": \"gpt-4\", \"type\": \"ai\"}, \"reference_contexts\": [\"This is a sample context\"], \"reference_answer\": \"Yes it is.\", \"reference_answer_by\": {\"model_name\": \"\", \"type\": \"human\"}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:06:57.137897Z",
     "start_time": "2024-06-02T14:06:57.134689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"This is a test query, is it so?\"\n",
    "reference_answer = \"I think yes, it is.\"\n",
    "reference_contexts = [\"This is a second sample context\"]\n",
    "\n",
    "rag_example_2 = LabelledRagDataExample(\n",
    "    query=query,\n",
    "    query_by=query_by,\n",
    "    reference_contexts=reference_contexts,\n",
    "    reference_answer=reference_answer,\n",
    "    reference_answer_by=reference_answer_by,\n",
    ")"
   ],
   "id": "1ecd0833abc1913c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:06:57.141810Z",
     "start_time": "2024-06-02T14:06:57.139550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "\n",
    "rag_dataset = LabelledRagDataset(examples=[rag_example, rag_example_2])"
   ],
   "id": "ed124507d3655453",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:06:57.163999Z",
     "start_time": "2024-06-02T14:06:57.148820Z"
    }
   },
   "cell_type": "code",
   "source": "rag_dataset.to_pandas()",
   "id": "2a2be13a47d8bd7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              query                 reference_contexts  \\\n",
       "0  This is a test query, is it not?         [This is a sample context]   \n",
       "1   This is a test query, is it so?  [This is a second sample context]   \n",
       "\n",
       "      reference_answer reference_answer_by    query_by  \n",
       "0           Yes it is.               human  ai (gpt-4)  \n",
       "1  I think yes, it is.               human  ai (gpt-4)  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test query, is it not?</td>\n",
       "      <td>[This is a sample context]</td>\n",
       "      <td>Yes it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a test query, is it so?</td>\n",
       "      <td>[This is a second sample context]</td>\n",
       "      <td>I think yes, it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:06:57.170768Z",
     "start_time": "2024-06-02T14:06:57.165443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "id": "d1ffcf01d6ff6e8a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:07:50.826913Z",
     "start_time": "2024-06-02T14:07:39.131821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup models\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# ollama\n",
    "Settings.llm = Ollama(model=\"llama3\", request_timeout=360.0)\n"
   ],
   "id": "286871b9f03ccbd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc32fabc0cce495b83a39052c97096c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65f7b78b2e6b42ebbc9e992024d2218e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a1fa5729a1a42999215af5d2f056c86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d79cccdc37747b69bb1772316654147"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakubkucera_1/Documents/diplomka/llm-rag-dip/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d17ed316c434d1f80601634ec80a29f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d80b976c31f42548e59b59b06e4ec4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1224ee3104864bc6ae7a3a3a4c7c326e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad04ef94ff0844d0914acddc856f99e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7987a7a6965f41bebd696cbd6f5cd3ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1532ff66b4e4ca9bd50a1e798ae06e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19518d86bd8c4faba71f9a90213478c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:08:33.052180Z",
     "start_time": "2024-06-02T14:08:29.354751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wikipedia pages\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "cities = [\n",
    "    \"San Francisco\",\n",
    "]\n",
    "\n",
    "documents = WikipediaReader().load_data(\n",
    "    pages=[f\"History of {x}\" for x in cities]\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ],
   "id": "ec5fbb2aeb4cbbae",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:09:55.830616Z",
     "start_time": "2024-06-02T14:09:30.381454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What's the population of San Francisco?\")\n",
    "print(response)"
   ],
   "id": "da1ac6cde5365190",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help! However, I don't see a specific mention of the current population of San Francisco in the provided context. The text does mention that the city is one of America's most expensive places to live, but it doesn't provide a numerical value for the population. If you're looking for an estimate or recent data on the population of San Francisco, I'd be happy to help you find that information!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:14:25.536901Z",
     "start_time": "2024-06-02T14:14:24.381298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate questions against chunks\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "\n",
    "# instantiate a DatasetGenerator\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    llm=Settings.llm,\n",
    "    num_questions_per_chunk=2,  # set the number of questions per nodes\n",
    "    show_progress=True,\n",
    ")"
   ],
   "id": "e01d3ab5fec2f5f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbb689b9a935447e869fdb9230cf6568"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:19:07.265989Z",
     "start_time": "2024-06-02T14:14:49.607487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# since there are 13 nodes, there should be a total of 26 questions\n",
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ],
   "id": "d66cf26afca51b58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:50<00:00,  8.48s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.75s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.84s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.66s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.30s/it]\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.32s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.52s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.99s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.03s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.30s/it]\n",
      "100%|██████████| 2/2 [00:16<00:00,  8.08s/it]\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.73s/it]\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.28s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.84s/it]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:19:50.481384Z",
     "start_time": "2024-06-02T14:19:50.468507Z"
    }
   },
   "cell_type": "code",
   "source": "rag_dataset.to_pandas()",
   "id": "a03148d95f21ee2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                query  \\\n",
       "0   Here are two questions I've generated based on...   \n",
       "1                                         Question 1:   \n",
       "2   Here are two questions that cover different as...   \n",
       "3                                      **Question 1**   \n",
       "4   Here are two questions that cover different as...   \n",
       "5                                         Question 1:   \n",
       "6   Here are two questions that cover different as...   \n",
       "7   **Question 1:** What was the name of the surge...   \n",
       "8   Based on the context information, I've generat...   \n",
       "9                                      **Question 1**   \n",
       "10  Here are two questions that I have generated b...   \n",
       "11                                     **Question 1**   \n",
       "12  Based on the context information, I've crafted...   \n",
       "13                                     **Question 1**   \n",
       "14  Here are two questions based on the given cont...   \n",
       "15                                        Question 1:   \n",
       "16  Here are two questions based on the context in...   \n",
       "17                                     **Question 1**   \n",
       "18  Here are two questions I've generated based on...   \n",
       "19                                     **Question 1**   \n",
       "20   Here are two questions for the quiz/examination:   \n",
       "21                                     **Question 1**   \n",
       "22  Here are two questions that cover different to...   \n",
       "23                                        Question 1:   \n",
       "24  Here are two questions based on the context in...   \n",
       "25                                     **Question 1**   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [The history of the city of San Francisco, Cal...   \n",
       "1   [The history of the city of San Francisco, Cal...   \n",
       "2   [== Arrival of Europeans and early settlement ...   \n",
       "3   [== Arrival of Europeans and early settlement ...   \n",
       "4   [== 1848 gold rush ==\\n\\nThe California gold r...   \n",
       "5   [== 1848 gold rush ==\\n\\nThe California gold r...   \n",
       "6   [== Paris of the West ==\\n\\nIt was during the ...   \n",
       "7   [== Paris of the West ==\\n\\nIt was during the ...   \n",
       "8   [== Corruption and graft trials ==\\n\\nMayor Eu...   \n",
       "9   [== Corruption and graft trials ==\\n\\nMayor Eu...   \n",
       "10  [=== Reconstruction ===\\n\\nAlmost immediately ...   \n",
       "11  [=== Reconstruction ===\\n\\nAlmost immediately ...   \n",
       "12  [== Post-World War II ==\\n\\nAfter World War II...   \n",
       "13  [== Post-World War II ==\\n\\nAfter World War II...   \n",
       "14  [== 1960 – 1970s ==\\n\\n\\n=== \"Summer of Love\" ...   \n",
       "15  [== 1960 – 1970s ==\\n\\n\\n=== \"Summer of Love\" ...   \n",
       "16  [=== New public infrastructure ===\\nThe 1970s ...   \n",
       "17  [=== New public infrastructure ===\\nThe 1970s ...   \n",
       "18  [=== 1989 Loma Prieta earthquake ===\\n\\nOn Oct...   \n",
       "19  [=== 1989 Loma Prieta earthquake ===\\n\\nOn Oct...   \n",
       "20  [== 2010s ==\\nThe early 2000s and into the 201...   \n",
       "21  [== 2010s ==\\nThe early 2000s and into the 201...   \n",
       "22  [=== Cultural themes ===\\nBerglund, Barbara (2...   \n",
       "23  [=== Cultural themes ===\\nBerglund, Barbara (2...   \n",
       "24  [=== Gold rush & early days ===\\nHittell, John...   \n",
       "25  [=== Gold rush & early days ===\\nHittell, John...   \n",
       "\n",
       "                                     reference_answer reference_answer_by  \\\n",
       "0   Based on the provided context information, her...         ai (llama3)   \n",
       "1   What was the earliest evidence of human habita...         ai (llama3)   \n",
       "2   Based on the provided context information, I'l...         ai (llama3)   \n",
       "3   Based on the provided context information, I'l...         ai (llama3)   \n",
       "4   Here are the answers to the two questions:\\n\\n...         ai (llama3)   \n",
       "5   Based on the provided context information abou...         ai (llama3)   \n",
       "6   Based on the provided context information, I'l...         ai (llama3)   \n",
       "7   According to the provided context information,...         ai (llama3)   \n",
       "8   I'm happy to help! Since you're asking me to g...         ai (llama3)   \n",
       "9   Based on the provided context information, her...         ai (llama3)   \n",
       "10  Based on the context information, here are my ...         ai (llama3)   \n",
       "11  Based on the provided context information, I'l...         ai (llama3)   \n",
       "12  Here are the answers to your two questions bas...         ai (llama3)   \n",
       "13  Based on the provided context information, her...         ai (llama3)   \n",
       "14  Here are answers to the two questions:\\n\\n**Qu...         ai (llama3)   \n",
       "15  Based on the provided context information, her...         ai (llama3)   \n",
       "16  Here are my answers to the two questions:\\n\\n*...         ai (llama3)   \n",
       "17  **Question 1**: When was San Francisco's first...         ai (llama3)   \n",
       "18  Based on the provided context information abou...         ai (llama3)   \n",
       "19  Based on the provided context information abou...         ai (llama3)   \n",
       "20  Based on the provided context information, her...         ai (llama3)   \n",
       "21  Based on the provided context information, I'l...         ai (llama3)   \n",
       "22  A delightful challenge!\\n\\nSince you've provid...         ai (llama3)   \n",
       "23  A new challenge!\\n\\nSince I have no prior know...         ai (llama3)   \n",
       "24  Based on the context information, I'll do my b...         ai (llama3)   \n",
       "25  Based on the provided context information, I'l...         ai (llama3)   \n",
       "\n",
       "       query_by  \n",
       "0   ai (llama3)  \n",
       "1   ai (llama3)  \n",
       "2   ai (llama3)  \n",
       "3   ai (llama3)  \n",
       "4   ai (llama3)  \n",
       "5   ai (llama3)  \n",
       "6   ai (llama3)  \n",
       "7   ai (llama3)  \n",
       "8   ai (llama3)  \n",
       "9   ai (llama3)  \n",
       "10  ai (llama3)  \n",
       "11  ai (llama3)  \n",
       "12  ai (llama3)  \n",
       "13  ai (llama3)  \n",
       "14  ai (llama3)  \n",
       "15  ai (llama3)  \n",
       "16  ai (llama3)  \n",
       "17  ai (llama3)  \n",
       "18  ai (llama3)  \n",
       "19  ai (llama3)  \n",
       "20  ai (llama3)  \n",
       "21  ai (llama3)  \n",
       "22  ai (llama3)  \n",
       "23  ai (llama3)  \n",
       "24  ai (llama3)  \n",
       "25  ai (llama3)  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are two questions I've generated based on...</td>\n",
       "      <td>[The history of the city of San Francisco, Cal...</td>\n",
       "      <td>Based on the provided context information, her...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question 1:</td>\n",
       "      <td>[The history of the city of San Francisco, Cal...</td>\n",
       "      <td>What was the earliest evidence of human habita...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here are two questions that cover different as...</td>\n",
       "      <td>[== Arrival of Europeans and early settlement ...</td>\n",
       "      <td>Based on the provided context information, I'l...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[== Arrival of Europeans and early settlement ...</td>\n",
       "      <td>Based on the provided context information, I'l...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here are two questions that cover different as...</td>\n",
       "      <td>[== 1848 gold rush ==\\n\\nThe California gold r...</td>\n",
       "      <td>Here are the answers to the two questions:\\n\\n...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Question 1:</td>\n",
       "      <td>[== 1848 gold rush ==\\n\\nThe California gold r...</td>\n",
       "      <td>Based on the provided context information abou...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Here are two questions that cover different as...</td>\n",
       "      <td>[== Paris of the West ==\\n\\nIt was during the ...</td>\n",
       "      <td>Based on the provided context information, I'l...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>**Question 1:** What was the name of the surge...</td>\n",
       "      <td>[== Paris of the West ==\\n\\nIt was during the ...</td>\n",
       "      <td>According to the provided context information,...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>[== Corruption and graft trials ==\\n\\nMayor Eu...</td>\n",
       "      <td>I'm happy to help! Since you're asking me to g...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[== Corruption and graft trials ==\\n\\nMayor Eu...</td>\n",
       "      <td>Based on the provided context information, her...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here are two questions that I have generated b...</td>\n",
       "      <td>[=== Reconstruction ===\\n\\nAlmost immediately ...</td>\n",
       "      <td>Based on the context information, here are my ...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[=== Reconstruction ===\\n\\nAlmost immediately ...</td>\n",
       "      <td>Based on the provided context information, I'l...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Based on the context information, I've crafted...</td>\n",
       "      <td>[== Post-World War II ==\\n\\nAfter World War II...</td>\n",
       "      <td>Here are the answers to your two questions bas...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[== Post-World War II ==\\n\\nAfter World War II...</td>\n",
       "      <td>Based on the provided context information, her...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Here are two questions based on the given cont...</td>\n",
       "      <td>[== 1960 – 1970s ==\\n\\n\\n=== \"Summer of Love\" ...</td>\n",
       "      <td>Here are answers to the two questions:\\n\\n**Qu...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Question 1:</td>\n",
       "      <td>[== 1960 – 1970s ==\\n\\n\\n=== \"Summer of Love\" ...</td>\n",
       "      <td>Based on the provided context information, her...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>[=== New public infrastructure ===\\nThe 1970s ...</td>\n",
       "      <td>Here are my answers to the two questions:\\n\\n*...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[=== New public infrastructure ===\\nThe 1970s ...</td>\n",
       "      <td>**Question 1**: When was San Francisco's first...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Here are two questions I've generated based on...</td>\n",
       "      <td>[=== 1989 Loma Prieta earthquake ===\\n\\nOn Oct...</td>\n",
       "      <td>Based on the provided context information abou...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[=== 1989 Loma Prieta earthquake ===\\n\\nOn Oct...</td>\n",
       "      <td>Based on the provided context information abou...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here are two questions for the quiz/examination:</td>\n",
       "      <td>[== 2010s ==\\nThe early 2000s and into the 201...</td>\n",
       "      <td>Based on the provided context information, her...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[== 2010s ==\\nThe early 2000s and into the 201...</td>\n",
       "      <td>Based on the provided context information, I'l...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Here are two questions that cover different to...</td>\n",
       "      <td>[=== Cultural themes ===\\nBerglund, Barbara (2...</td>\n",
       "      <td>A delightful challenge!\\n\\nSince you've provid...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Question 1:</td>\n",
       "      <td>[=== Cultural themes ===\\nBerglund, Barbara (2...</td>\n",
       "      <td>A new challenge!\\n\\nSince I have no prior know...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>[=== Gold rush &amp; early days ===\\nHittell, John...</td>\n",
       "      <td>Based on the context information, I'll do my b...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>**Question 1**</td>\n",
       "      <td>[=== Gold rush &amp; early days ===\\nHittell, John...</td>\n",
       "      <td>Based on the provided context information, I'l...</td>\n",
       "      <td>ai (llama3)</td>\n",
       "      <td>ai (llama3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4ba5bd9d2441e85d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
